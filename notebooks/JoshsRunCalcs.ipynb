{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for XSEDE proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resource usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from yt import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of cells in the simulation.\n",
    "Assume the zoom in leaves us 384 blocks in the inner zoomed region for ~50 pc^3 area,\n",
    "which is what we get for the Bullhead cloud.\n",
    "\n",
    "After that the volume filling fraction is about 1/8, so the number of blocks generally doubles per level of refinement. Here we use 2.5 to be safe (which was what Olson put in the original NSF proposal).\n",
    "\n",
    "Also assume blocks have 16^3 cells in each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "960.0\n",
      "2\n",
      "2400.0\n",
      "3\n",
      "6000.0\n",
      "4\n",
      "15000.0\n",
      "5\n",
      "37500.0\n",
      "6\n",
      "93750.0\n",
      "7\n",
      "234375.0\n",
      "393869.0 blocks total.\n",
      "1969.345\n",
      "1969.345\n",
      "1613287424.0 cells in the simulation after fragmentation.\n"
     ]
    }
   ],
   "source": [
    "lzoom=5\n",
    "lmax=12\n",
    "\n",
    "factor = 2.5\n",
    "\n",
    "blksPerProc = 200\n",
    "\n",
    "# Number of blocks for 50 pc zoom in region, based on the bull head cloud.\n",
    "# These are all the background blocks that *don't* include the zoomed region.\n",
    "numBlksOuter=3500\n",
    "\n",
    "# Now the zoomed region at 5 levels of refinement and over a 50 pc region square\n",
    "# should cover about 4^3=64 blocks. Then from there each level should just more than double the\n",
    "# last level. But for some reason the first level in (lef=6) has 364 blocks, not\n",
    "# 64*2.5=160 blocks. After that though it follows the 2.5 rule pretty well.\n",
    "\n",
    "numBlksZoom1=384\n",
    "\n",
    "numBlksLevel = numBlksZoom1\n",
    "\n",
    "numBlksZoomTotal = numBlksZoom1\n",
    "\n",
    "# Number of blocks if we assume a cloud that is an order magnitude larger has twice the\n",
    "# radius and therefore 2^3 times more blocks. This is likely conservative, since the\n",
    "# cloud is probably more dense and not as large.\n",
    "numBlksBig=numBlksZoom1*(2^3)\n",
    "\n",
    "\n",
    "# Each level has factor*numBlksPreviousLevel number of blocks.\n",
    "# Here we sum up those blocks to get the total. Note we start\n",
    "# with only those blocks in the region we zoomed in on!\n",
    "# Previously we mistakingly calculated it with all the blocks\n",
    "# at the previous level.\n",
    "for i in range(1, lmax-lzoom+1):\n",
    "    \n",
    "    print i\n",
    "    \n",
    "    numBlksLevel = factor*numBlksLevel\n",
    "     \n",
    "    numBlksZoomTotal = numBlksZoomTotal + numBlksLevel\n",
    "    \n",
    "    print numBlksLevel\n",
    "    \n",
    "numBlksTotal = numBlksZoomTotal + numBlksOuter\n",
    "    \n",
    "print numBlksTotal, \"blocks total.\"\n",
    "\n",
    "print numBlksTotal/blksPerProc\n",
    "\n",
    "numCells =  numBlksTotal*(16**3)\n",
    "\n",
    "blksPerProc = 200\n",
    "\n",
    "print numBlksTotal/blksPerProc\n",
    "\n",
    "print numCells, \"cells in the simulation after fragmentation.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we calculate the average timestep assuming that the highest temperature is due to the radaition feedback. We assume it takes 2 Myr for the gas to collapse to the Jeans criterion at the highest level of refinement and star formation to start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2393409.3641 23934093.641\n",
      "7.47989353754e+15\n",
      "99.031752283 years for low temp timesteps\n",
      "9.9031752283 years for high temp timesteps\n",
      "826505.933064 steps in the simulation\n"
     ]
    }
   ],
   "source": [
    "# Temp.\n",
    "lowT = 10e4 * units.K\n",
    "highT = 10e6 * units.K\n",
    "\n",
    "# Sound speed.\n",
    "csLow = np.sqrt(5./3. *units.boltzmann_constant_cgs.v*lowT.v /(2.4* units.mass_hydrogen_cgs.v))\n",
    "csHigh = np.sqrt(5./3. *units.boltzmann_constant_cgs.v*highT.v /(2.4* units.mass_hydrogen_cgs.v))\n",
    "\n",
    "print csLow, csHigh\n",
    "\n",
    "# 500 AU cell size at highest refinement.\n",
    "dx = 500 * units.AU.in_cgs().v\n",
    "\n",
    "print dx\n",
    "\n",
    "# Timestep.\n",
    "lowTS = dx/csLow\n",
    "highTS = dx/csHigh\n",
    "\n",
    "print lowTS/(60*60*24*365.25), \"years for low temp timesteps\"\n",
    "print highTS/(60*60*24*365.25), \"years for high temp timesteps\"\n",
    "\n",
    "\n",
    "Myr = 3.15e13\n",
    "\n",
    "#Myr = 15*Myr\n",
    "\n",
    "# Number of steps for a 10 Myr simulation.\n",
    "numSteps = 2*Myr/lowTS + 8*Myr/highTS\n",
    "\n",
    "print numSteps, \"steps in the simulation\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we calculate the amount of computer time needed to do the simulation. Here we assume:\n",
    "\n",
    "1) An average Flash MHD update takes ~150 microseconds (Olson's timing).\n",
    "\n",
    "2) An average radiation takes about the same amount of time as an MHD update (Wise & Abel 2011, Stone @ PiTP 2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.11e+08 hrs is total CPU time\n"
     ]
    }
   ],
   "source": [
    "timePerStep = 300e-6\n",
    "#procSpeed = 3e9\n",
    "hr = 60*60\n",
    "\n",
    "print \"{:.2e}\".format(numSteps*numCells*timePerStep/hr), \"hrs is total CPU time\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Storage requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume that we make a plot file every 10,000 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29744.2064881\n"
     ]
    }
   ],
   "source": [
    "pltFreq = 1e5\n",
    "runTime = 1e7\n",
    "numPlots = runTime/pltFreq\n",
    "\n",
    "numHyVars = 30\n",
    "numCells = numCells\n",
    "numPartVars = 15\n",
    "numParts = 1e4\n",
    "\n",
    "\n",
    "\n",
    "sizeOfVar = 64\n",
    "sizeOfGB = 2.**30\n",
    "\n",
    "tempStorage = numPlots*(numHyVars*numCells+numPartVars*numParts)*sizeOfVar/sizeOfGB\n",
    "\n",
    "print tempStorage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
