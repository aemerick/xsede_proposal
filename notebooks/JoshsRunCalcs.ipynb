{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for XSEDE proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resource usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'yt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-11e64b3e7965>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0myt\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'yt'"
     ]
    }
   ],
   "source": [
    "from yt import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of cells in the simulation.\n",
    "Assume the zoom in leaves us 384 blocks in the inner zoomed region for ~50 pc^3 area,\n",
    "which is what we get for the Bullhead cloud.\n",
    "\n",
    "After that the volume filling fraction is about 1/8, so the number of blocks generally doubles per level of refinement. Here we use 2.5 to be safe (which was what Olson put in the original NSF proposal).  [***factor = 2.0 in the notebook, though***]\n",
    "\n",
    "Also assume blocks have 16^3 cells in each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "768.0\n",
      "2\n",
      "1536.0\n",
      "3\n",
      "3072.0\n",
      "4\n",
      "6144.0\n",
      "5\n",
      "12288.0\n",
      "6\n",
      "24576.0\n",
      "7\n",
      "49152.0\n",
      "101420.0 blocks total.\n",
      "507.1\n",
      "202.84\n",
      "415416320.0 cells in the simulation after fragmentation.\n"
     ]
    }
   ],
   "source": [
    "lzoom=5\n",
    "lmax=12\n",
    "\n",
    "num_zoom_lvls = 9 #lmax-lzoom\n",
    "\n",
    "factor = 2.0\n",
    "\n",
    "blksPerProc = 200\n",
    "\n",
    "# Number of blocks for 50 pc zoom in region, based on the bull head cloud.\n",
    "# These are all the background blocks that *don't* include the zoomed region.\n",
    "numBlksOuter=3500\n",
    "\n",
    "# Now the zoomed region at 5 levels of refinement and over a 50 pc region square\n",
    "# should cover about 4^3=64 blocks. Then from there each level should just more than double the\n",
    "# last level. But for some reason the first level in (lef=6) has 364 blocks, not\n",
    "# 64*2.5=160 blocks. After that though it follows the 2.5 rule pretty well.\n",
    "\n",
    "numBlksZoom1=384\n",
    "\n",
    "numBlksLevel = numBlksZoom1\n",
    "\n",
    "numBlksZoomTotal = numBlksZoom1\n",
    "\n",
    "# Number of blocks if we assume a cloud that is an order magnitude larger has twice the\n",
    "# radius and therefore 2^3 times more blocks. This is likely conservative, since the\n",
    "# cloud is probably more dense and not as large.\n",
    "numBlksBig=numBlksZoom1*(2^3)\n",
    "\n",
    "\n",
    "# Each level has factor*numBlksPreviousLevel number of blocks.\n",
    "# Here we sum up those blocks to get the total. Note we start\n",
    "# with only those blocks in the region we zoomed in on!\n",
    "# Previously we mistakingly calculated it with all the blocks\n",
    "# at the previous level.\n",
    "\n",
    "# Note here we started at lzoom + 1 so no need to add 1 anymore.\n",
    "\n",
    "for i in range(1, num_zoom_lvls-1):\n",
    "    \n",
    "    print i\n",
    "    \n",
    "    numBlksLevel = factor*numBlksLevel\n",
    "     \n",
    "    numBlksZoomTotal = numBlksZoomTotal + numBlksLevel\n",
    "    \n",
    "    print numBlksLevel\n",
    "    \n",
    "numBlksTotal = numBlksZoomTotal + numBlksOuter\n",
    "    \n",
    "print numBlksTotal, \"blocks total.\"\n",
    "\n",
    "print numBlksTotal/blksPerProc\n",
    "\n",
    "numCells =  numBlksTotal*(16**3)\n",
    "\n",
    "blksPerProc = 500.\n",
    "\n",
    "print numBlksTotal/blksPerProc\n",
    "\n",
    "print numCells, \"cells in the simulation after fragmentation.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we calculate the average timestep assuming that the highest temperature is due to the radaition feedback. We assume it takes 2 Myr for the gas to collapse to the Jeans criterion at the highest level of refinement and star formation to start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'units' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-af8c00dfd55f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Temp.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlowT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e4\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0munits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mK\u001b[0m   \u001b[0;31m#corrected from 10e4 = 1e5  M-MML 22:15 14 Oct 16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mhighT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e6\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0munits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mK\u001b[0m  \u001b[0;31m#               10e6 = 1e7\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmu_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.62\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'units' is not defined"
     ]
    }
   ],
   "source": [
    "# Temp.\n",
    "lowT = 1e4 * units.K   #corrected from 10e4 = 1e5  M-MML 22:15 14 Oct 16\n",
    "highT = 1e6 * units.K  #               10e6 = 1e7\n",
    "\n",
    "mu_i = 0.62\n",
    "mu_n = 2.4\n",
    "\n",
    "# Sound speed.\n",
    "csLow = np.sqrt(5./3. *units.boltzmann_constant_cgs.v*lowT.v /(mu_n* units.mass_hydrogen_cgs.v))\n",
    "csHigh = np.sqrt(5./3. *units.boltzmann_constant_cgs.v*highT.v /(mu_i* units.mass_hydrogen_cgs.v))\n",
    "\n",
    "print (csLow/1.0e5, csHigh/1.0e5)  #km/s\n",
    "\n",
    "# 500 AU cell size at highest refinement.\n",
    "dx = 1577 * units.AU.in_cgs().v\n",
    "\n",
    "print dx, \"is cell width in cm\"\n",
    "\n",
    "# Timestep.\n",
    "lowTS = dx/csLow\n",
    "highTS = dx/csHigh\n",
    "\n",
    "print lowTS/(60*60*24*365.25), \"years for low temp timesteps\"\n",
    "print highTS/(60*60*24*365.25), \"years for high temp timesteps\"\n",
    "\n",
    "\n",
    "Myr = 3.15e13\n",
    "\n",
    "# Number of steps for a 10 Myr simulation.\n",
    "numSteps = 2*Myr/lowTS + 8*Myr/highTS\n",
    "\n",
    "print numSteps, \"steps in the simulation\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we calculate the amount of computer time needed to do the simulation. Here we assume:\n",
    "\n",
    "1) An average Flash MHD update takes ~150 microseconds (Olson's timing). [***so why is timePerStep = 300e-6 rather than 150e-6?***]\n",
    "\n",
    "2) An average radiation takes about the same amount of time as an MHD update (Wise & Abel 2011, Stone @ PiTP 2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.76e+07 hrs is total CPU time\n"
     ]
    }
   ],
   "source": [
    "timePerStep = 300e-6\n",
    "#procSpeed = 3e9\n",
    "hr = 60*60\n",
    "\n",
    "print \"{:.2e}\".format(numSteps*numCells*timePerStep/hr), \"hrs is total CPU time\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Storage requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume that we make a plot file every 10,000 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29744.2064881\n"
     ]
    }
   ],
   "source": [
    "pltFreq = 1e5\n",
    "runTime = 1e7\n",
    "numPlots = runTime/pltFreq\n",
    "\n",
    "numHyVars = 30\n",
    "numCells = numCells\n",
    "numPartVars = 15\n",
    "numParts = 1e4\n",
    "\n",
    "\n",
    "\n",
    "sizeOfVar = 64\n",
    "sizeOfGB = 2.**30\n",
    "\n",
    "tempStorage = numPlots*(numHyVars*numCells+numPartVars*numParts)*sizeOfVar/sizeOfGB\n",
    "\n",
    "print tempStorage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
